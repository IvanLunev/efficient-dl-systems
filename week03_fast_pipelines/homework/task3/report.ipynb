{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use PyTorch Profiler With TensorBoard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first profiling I got very slow tensorboard work, so I changed batch size to 32. I got the next profile:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](results/bs_32.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspectiong we can say:\n",
    "* Average times: ```Embedding layer```: 270us, ```self-attention```: 220us and ```feed-forward```: 130us\n",
    "* ```Softmax``` and ```GELU``` have 36 calls each and approximately the same time\n",
    "* ```backward``` takes two time more time, than ```forward```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image preprocessing ```resize``` takes a lot of time. After checking the code I changed default interpolation method to ```transforms.InterpolationMode.NEAREST```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the main timeconcuming operation in preprocessing is still resize. The original images are big, so I do not think, that it is possible reduce the time. But it is posseble to increase the number of workers. I set ```num_workers=16```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I got:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](results/w_16.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found, that accuracy during training and evaluation calculated without ```with torch.no_grad():```. Added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting shapes saw some shapes with 255 size. It can lead to inefficient use of memory, so changed to 256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also found, that query-key-value was calculated by separate ```nn.Linear```, but this is not efficient. So a changed to one ```nn.Linear```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the training takes now less than 30 sec, but it looks like the dataloader sometimes freeze and a can't understand why :( I thought this is because of GIL, but I it seems it shoudn't. So, there are should be more bugs I haven't found... I hope you tell me the remaining after reviewing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
